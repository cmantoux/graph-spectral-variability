"""
This file includes functions to sample from von Mises-Fisher densities
and perform Maximum Likelihood Estimation of their parameters.
"""

import numpy as np
from scipy.optimize import minimize
from tqdm.auto import *

import src.stiefel as st
from src import spa


def log_von_mises_fisher(Y, F, normalized=False):
    """von Mises-Fisher log-density on the Stiefel Manifold"""
    if normalized:
        return (Y*F).sum() - spa.log_vmf(F)
    else:
        return (Y*F).sum()

def sample_von_mises_fisher(F, n_iter=100, burn=100, stride=10, progress=False):
    """
    Sample from the vMF distribution using an adaptive Metropolis-Hastings algorithm.
    """
    X = st.proj_V(F) # Initialize at the mode of the distribution to ensure a fast convergence.
    s = np.linalg.svd(F, compute_uv=False)
    n, p = F.shape
    Xs = np.zeros((n_iter, n, p))
    current_lk = (X*F).sum()
    accepts = 0
    
    # Adaptive parameters: the proposal variance is tuned along the MCMC
    std = 0.4
    batch = 100
    accepts_hist = np.zeros(batch)
    optimal_rate = 0.234
    
    total_steps = burn+n_iter*stride
    it = trange(total_steps) if progress else range(total_steps)
    for t in it:
        # The proposal is generated by adding non-manifold noise and projecting back onto the manifold.
        D = std * np.random.randn(n, p)/s
        X2 = st.proj_V(X + D)
        new_lk = (X2*F).sum()
        
        if new_lk - current_lk > np.log(np.random.rand()):
            X = X2
            current_lk = new_lk
            accepts += 1
            accepts_hist[t%batch] = 1
        else:
            accepts_hist[t%batch] = 0
        
        if t >= burn and (t-burn)%stride==0:
            Xs[(t-burn)//stride] = X
        
        if t%batch==0 and t>0:
            adapt = 2*(accepts_hist.mean() > optimal_rate) - 1
            std = np.exp(np.log(std) + adapt/np.sqrt(t))
            
    if progress: print(f"VMF Acceptance rate: {accepts/(burn+n_iter*stride)}")
    return Xs


def mle(X_bar, orth=False, upper_sv=500):
    """Maximum Likelihood Estimate of samples of a vMF distribution from their Euclidean mean X_bar."""
    
    n, p = X_bar.shape
    u, g, v = np.linalg.svd(X_bar, full_matrices=False)
    if orth: # if True, constrains the columns of the MLE F to be orthogonal
        u = u@v
        v = np.eye(p)

    def mle_objective(s):
        F = u@np.diag(s)@v
        C = spa.log_vmf(F)
        res = (X_bar*F).sum() - C
        return -res
    
    res = minimize(mle_objective, x0=g, tol=1e-5, bounds=[(1e-2,upper_sv)]*p)
    s = res['x']
    
    return u@np.diag(s)@v